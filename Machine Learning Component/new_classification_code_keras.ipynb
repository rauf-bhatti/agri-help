{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0467d297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6007b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model():\n",
    "    train_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "        \"Cotton_Leaf_Dataset/cotton/train/\",\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=1337,\n",
    "        image_size=(256, 256),\n",
    "        batch_size=32,\n",
    "    )\n",
    "    \n",
    "    val_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "        \"Cotton_Leaf_Dataset/cotton/val/\",\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        seed=1337,\n",
    "        image_size=(256, 256),\n",
    "        batch_size=32,\n",
    "    )\n",
    "    \n",
    "    num_classes = 4\n",
    "    train_ds = train_ds.map(lambda x, y: (x, tf.one_hot(y, num_classes)))\n",
    "\n",
    "    # Assuming `val_ds` is a `BatchDataset` containing image batches and labels\n",
    "    val_ds = val_ds.map(lambda x, y: (x, tf.one_hot(y, num_classes)))\n",
    "    # Data augmentation\n",
    "    data_augmentation = keras.Sequential(\n",
    "        [\n",
    "            layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "            layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "            layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Define the model\n",
    "    model = keras.Sequential([\n",
    "        data_augmentation,\n",
    "        layers.experimental.preprocessing.Rescaling(1./255),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(256,256,3)),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    epochs = 50\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=epochs\n",
    "    )\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_ds = keras.preprocessing.image_dataset_from_directory(\n",
    "        \"Cotton_Leaf_Dataset/cotton/test/\",\n",
    "        seed=1337,\n",
    "        image_size=(256, 256),\n",
    "        batch_size=32,\n",
    "    )\n",
    "    \n",
    "    test_ds = test_ds.map(lambda x, y: (x, tf.one_hot(y, num_classes)))\n",
    "    test_loss, test_acc = model.evaluate(test_ds, verbose=2)\n",
    "    print(\"Test accuracy:\", test_acc)\n",
    "    model.save(\"cnn_fyp2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d9b453a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    run_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4fd66c09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1630 files belonging to 4 classes.\n",
      "Using 1304 files for training.\n",
      "Found 47 files belonging to 4 classes.\n",
      "Using 9 files for validation.\n",
      "Epoch 1/50\n",
      "41/41 [==============================] - 74s 2s/step - loss: 1.7305 - accuracy: 0.4256 - val_loss: 0.8778 - val_accuracy: 0.4444\n",
      "Epoch 2/50\n",
      "41/41 [==============================] - 67s 2s/step - loss: 0.8481 - accuracy: 0.6664 - val_loss: 0.6699 - val_accuracy: 0.6667\n",
      "Epoch 3/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 0.7233 - accuracy: 0.7025 - val_loss: 0.5715 - val_accuracy: 0.6667\n",
      "Epoch 4/50\n",
      "41/41 [==============================] - 68s 2s/step - loss: 0.7178 - accuracy: 0.7209 - val_loss: 0.4798 - val_accuracy: 0.7778\n",
      "Epoch 5/50\n",
      "41/41 [==============================] - 70s 2s/step - loss: 0.4944 - accuracy: 0.8067 - val_loss: 0.4158 - val_accuracy: 0.8889\n",
      "Epoch 6/50\n",
      "41/41 [==============================] - 63s 2s/step - loss: 0.4481 - accuracy: 0.8359 - val_loss: 0.5162 - val_accuracy: 0.7778\n",
      "Epoch 7/50\n",
      "41/41 [==============================] - 62s 2s/step - loss: 0.3630 - accuracy: 0.8673 - val_loss: 0.3370 - val_accuracy: 0.7778\n",
      "Epoch 8/50\n",
      "41/41 [==============================] - 60s 1s/step - loss: 0.2865 - accuracy: 0.8919 - val_loss: 0.3236 - val_accuracy: 0.8889\n",
      "Epoch 9/50\n",
      "41/41 [==============================] - 61s 1s/step - loss: 0.2997 - accuracy: 0.8842 - val_loss: 0.3324 - val_accuracy: 0.8889\n",
      "Epoch 10/50\n",
      "41/41 [==============================] - 60s 1s/step - loss: 0.2488 - accuracy: 0.9095 - val_loss: 0.2941 - val_accuracy: 0.8889\n",
      "Epoch 11/50\n",
      "41/41 [==============================] - 61s 1s/step - loss: 0.2262 - accuracy: 0.9195 - val_loss: 0.1066 - val_accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "41/41 [==============================] - 67s 2s/step - loss: 0.1899 - accuracy: 0.9310 - val_loss: 0.1613 - val_accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "41/41 [==============================] - 59s 1s/step - loss: 0.1582 - accuracy: 0.9433 - val_loss: 0.3856 - val_accuracy: 0.8889\n",
      "Epoch 14/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.1451 - accuracy: 0.9571 - val_loss: 0.1280 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.1120 - accuracy: 0.9601 - val_loss: 0.1593 - val_accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.1442 - accuracy: 0.9494 - val_loss: 0.5353 - val_accuracy: 0.8889\n",
      "Epoch 17/50\n",
      "41/41 [==============================] - 59s 1s/step - loss: 0.1289 - accuracy: 0.9517 - val_loss: 0.1888 - val_accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.0985 - accuracy: 0.9663 - val_loss: 0.2544 - val_accuracy: 0.8889\n",
      "Epoch 19/50\n",
      "41/41 [==============================] - 59s 1s/step - loss: 0.0814 - accuracy: 0.9693 - val_loss: 0.4421 - val_accuracy: 0.8889\n",
      "Epoch 20/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.1066 - accuracy: 0.9663 - val_loss: 0.1939 - val_accuracy: 0.8889\n",
      "Epoch 21/50\n",
      "41/41 [==============================] - 57s 1s/step - loss: 0.0645 - accuracy: 0.9808 - val_loss: 0.1948 - val_accuracy: 0.8889\n",
      "Epoch 22/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.0730 - accuracy: 0.9755 - val_loss: 0.2060 - val_accuracy: 0.8889\n",
      "Epoch 23/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.0579 - accuracy: 0.9785 - val_loss: 0.4466 - val_accuracy: 0.8889\n",
      "Epoch 24/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.0526 - accuracy: 0.9824 - val_loss: 0.3653 - val_accuracy: 0.7778\n",
      "Epoch 25/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.0612 - accuracy: 0.9801 - val_loss: 0.2490 - val_accuracy: 0.7778\n",
      "Epoch 26/50\n",
      "41/41 [==============================] - 59s 1s/step - loss: 0.0595 - accuracy: 0.9801 - val_loss: 0.0896 - val_accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "41/41 [==============================] - 59s 1s/step - loss: 0.0493 - accuracy: 0.9862 - val_loss: 0.5750 - val_accuracy: 0.7778\n",
      "Epoch 28/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.1161 - accuracy: 0.9678 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.1371 - accuracy: 0.9578 - val_loss: 0.0837 - val_accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.0595 - accuracy: 0.9839 - val_loss: 0.0463 - val_accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.0328 - accuracy: 0.9862 - val_loss: 0.0297 - val_accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.0678 - accuracy: 0.9747 - val_loss: 0.2442 - val_accuracy: 0.8889\n",
      "Epoch 33/50\n",
      "41/41 [==============================] - 59s 1s/step - loss: 0.0527 - accuracy: 0.9816 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.0493 - accuracy: 0.9831 - val_loss: 0.3055 - val_accuracy: 0.8889\n",
      "Epoch 35/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.1111 - accuracy: 0.9632 - val_loss: 0.1998 - val_accuracy: 0.8889\n",
      "Epoch 36/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.0491 - accuracy: 0.9839 - val_loss: 0.4927 - val_accuracy: 0.8889\n",
      "Epoch 37/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.0405 - accuracy: 0.9893 - val_loss: 0.1161 - val_accuracy: 0.8889\n",
      "Epoch 38/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.0499 - accuracy: 0.9870 - val_loss: 0.1599 - val_accuracy: 0.8889\n",
      "Epoch 39/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.0261 - accuracy: 0.9923 - val_loss: 0.1864 - val_accuracy: 0.8889\n",
      "Epoch 40/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.0300 - accuracy: 0.9900 - val_loss: 0.1321 - val_accuracy: 0.8889\n",
      "Epoch 41/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.0202 - accuracy: 0.9946 - val_loss: 0.1520 - val_accuracy: 0.8889\n",
      "Epoch 42/50\n",
      "41/41 [==============================] - 59s 1s/step - loss: 0.0304 - accuracy: 0.9923 - val_loss: 0.3487 - val_accuracy: 0.7778\n",
      "Epoch 43/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.0191 - accuracy: 0.9931 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.0450 - accuracy: 0.9862 - val_loss: 0.1284 - val_accuracy: 0.8889\n",
      "Epoch 45/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.0601 - accuracy: 0.9808 - val_loss: 0.5239 - val_accuracy: 0.8889\n",
      "Epoch 46/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.0595 - accuracy: 0.9778 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.1619 - accuracy: 0.9486 - val_loss: 0.1059 - val_accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.1462 - accuracy: 0.9433 - val_loss: 0.0736 - val_accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "41/41 [==============================] - 58s 1s/step - loss: 0.0418 - accuracy: 0.9854 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "41/41 [==============================] - 57s 1s/step - loss: 0.0286 - accuracy: 0.9923 - val_loss: 0.0801 - val_accuracy: 1.0000\n",
      "Found 33 files belonging to 4 classes.\n",
      "2/2 - 1s - loss: 0.0413 - accuracy: 0.9697 - 1s/epoch - 600ms/step\n",
      "Test accuracy: 0.9696969985961914\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
